{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "plt.ion()  \n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using CUDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 266 images under train\n",
      "Loaded 152 images under val\n",
      "Loaded 247 images under test\n",
      "Classes: \n",
      "['0', '1']\n"
     ]
    }
   ],
   "source": [
    "data_dir = './small/'\n",
    "TRAIN = 'train'\n",
    "VAL = 'val'\n",
    "TEST = 'test'\n",
    "\n",
    "# VGG-16 Takes 224x224 images as input, so we resize all of them\n",
    "data_transforms = {\n",
    "    TRAIN: transforms.Compose([\n",
    "        # Data augmentation is a good practice for the train set\n",
    "        # Here, we randomly crop the image to 224x224 and\n",
    "        # randomly flip it horizontally. \n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    VAL: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    TEST: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(\n",
    "        os.path.join(data_dir, x), \n",
    "        transform=data_transforms[x]\n",
    "    )\n",
    "    for x in [TRAIN, VAL, TEST]\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x], batch_size=8,\n",
    "        shuffle=True, num_workers=4\n",
    "    )\n",
    "    for x in [TRAIN, VAL, TEST]\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL, TEST]}\n",
    "\n",
    "for x in [TRAIN, VAL, TEST]:\n",
    "    print(\"Loaded {} images under {}\".format(dataset_sizes[x], x))\n",
    "    \n",
    "print(\"Classes: \")\n",
    "class_names = image_datasets[TRAIN].classes\n",
    "print(image_datasets[TRAIN].classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    # plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "\n",
    "def show_databatch(inputs, classes):\n",
    "    out = torchvision.utils.make_grid(inputs)\n",
    "    imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders[TRAIN]))\n",
    "show_databatch(inputs, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(vgg, num_images=6):\n",
    "    was_training = vgg.training\n",
    "    \n",
    "    # Set model for evaluation\n",
    "    vgg.train(False)\n",
    "    vgg.eval() \n",
    "    \n",
    "    images_so_far = 0\n",
    "\n",
    "    for i, data in enumerate(dataloaders[TEST]):\n",
    "        inputs, labels = data\n",
    "        size = inputs.size()[0]\n",
    "        \n",
    "        if use_gpu:\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            with torch.no_grad():                                  \n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        outputs = vgg(inputs)\n",
    "        \n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        predicted_labels = [preds[j] for j in range(inputs.size()[0])]\n",
    "        \n",
    "        print(\"Ground truth:\")\n",
    "        show_databatch(inputs.data.cpu(), labels.data.cpu())\n",
    "        print(\"Prediction:\")\n",
    "        show_databatch(inputs.data.cpu(), predicted_labels)\n",
    "        \n",
    "        del inputs, labels, outputs, preds, predicted_labels\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        images_so_far += size\n",
    "        if images_so_far >= num_images:\n",
    "            break\n",
    "        \n",
    "    vgg.train(mode=was_training) # Revert model back to original training state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(vgg, criterion):\n",
    "    since = time.time()\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    loss_test = 0\n",
    "    acc_test = 0\n",
    "    \n",
    "    test_batches = len(dataloaders[TEST])\n",
    "    print(\"Evaluating model\")\n",
    "    print('-' * 10)\n",
    "    \n",
    "    for i, data in enumerate(dataloaders[TEST]):\n",
    "        if i % 100 == 0:\n",
    "            print(\"\\rTest batch {}/{}\".format(i, test_batches), end='', flush=True)\n",
    "\n",
    "        vgg.train(False)\n",
    "        vgg.eval()\n",
    "        inputs, labels = data\n",
    "\n",
    "        if use_gpu:\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        outputs = vgg(inputs)\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss_test += loss.item()\n",
    "        acc_test += torch.sum(torch.eq(preds,labels)).item()\n",
    "\n",
    "        del inputs, labels, outputs, preds\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    avg_loss = loss_test / dataset_sizes[TEST]\n",
    "    avg_acc = acc_test / dataset_sizes[TEST]\n",
    "    \n",
    "    elapsed_time = time.time() - since\n",
    "    print()\n",
    "    print(\"Evaluation completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print(\"Avg loss (test): {:.4f}\".format(avg_loss))\n",
    "    print(\"Avg acc (test): {:.4f}\".format(avg_acc))\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg16 = models.vgg16_bn()\n",
    "vgg16.load_state_dict(torch.load(\"./vgg16_bn.pth\"))\n",
    "print(vgg16.classifier[6].out_features) # 1000 \n",
    "\n",
    "\n",
    "# Freeze training for all layers\n",
    "for param in vgg16.features.parameters():\n",
    "    param.require_grad = False\n",
    "\n",
    "# Newly created modules have require_grad=True by default\n",
    "num_features = vgg16.classifier[6].in_features\n",
    "features = list(vgg16.classifier.children())[:-1] # Remove last layer\n",
    "features.extend([nn.Linear(num_features, len(class_names))]) # Add our layer with 4 outputs\n",
    "vgg16.classifier = nn.Sequential(*features) # Replace the model classifier\n",
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model..\n",
      "Loaded!\n"
     ]
    }
   ],
   "source": [
    "# If you want to train the model for more than 2 epochs, set this to True after the first run\n",
    "resume_training = True\n",
    "\n",
    "if resume_training:\n",
    "    print(\"Loading pretrained model..\")\n",
    "    vgg16.load_state_dict(torch.load('./Explore_Australia.pt'))\n",
    "    print(\"Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    vgg16.cuda() #.cuda() will move everything to the GPU side\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Test before training\")\n",
    "# eval_model(vgg16, criterion)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(vgg, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    avg_loss_val = 0\n",
    "    avg_acc_val = 0\n",
    "    \n",
    "    train_batches = len(dataloaders[TRAIN])\n",
    "    val_batches = len(dataloaders[VAL])\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        loss_train = 0\n",
    "        loss_val = 0\n",
    "        acc_train = 0\n",
    "        acc_val = 0\n",
    "        \n",
    "        vgg.train(True)\n",
    "        \n",
    "        for i, data in enumerate(dataloaders[TRAIN]):\n",
    "            if i % 100 == 0:\n",
    "                print(\"\\rTraining batch {}/{}\".format(i, train_batches / 2), end='', flush=True)\n",
    "                \n",
    "            # Use half training dataset\n",
    "            if i >= train_batches / 2:\n",
    "                break\n",
    "                \n",
    "            inputs, labels = data\n",
    "            \n",
    "            if use_gpu:\n",
    "                with torch.no_grad():\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = vgg(inputs)\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            acc_train += torch.sum(torch.eq(preds,labels)).item()\n",
    "            \n",
    "            del inputs, labels, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        print()\n",
    "        # * 2 as we only used half of the dataset\n",
    "        avg_loss = loss_train * 2 / dataset_sizes[TRAIN]\n",
    "        avg_acc = acc_train * 2 / dataset_sizes[TRAIN]\n",
    "        \n",
    "        vgg.train(False)\n",
    "        vgg.eval()\n",
    "            \n",
    "        for i, data in enumerate(dataloaders[VAL]):\n",
    "            if i % 100 == 0:\n",
    "                print(\"\\rValidation batch {}/{}\".format(i, val_batches), end='', flush=True)\n",
    "                \n",
    "            inputs, labels = data\n",
    "            \n",
    "            if use_gpu:\n",
    "                with torch.no_grad():\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = vgg(inputs)\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss_val += loss.item()\n",
    "            acc_val += torch.sum(torch.eq(preds,labels)).item()\n",
    "            \n",
    "            del inputs, labels, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        avg_loss_val = loss_val / dataset_sizes[VAL]\n",
    "        avg_acc_val = acc_val / dataset_sizes[VAL]\n",
    "        \n",
    "        print()\n",
    "        print(\"Epoch {} result: \".format(epoch))\n",
    "        print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n",
    "        print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n",
    "        print(\"Avg loss (val): {:.4f}\".format(avg_loss_val))\n",
    "        print(\"Avg acc (val): {:.4f}\".format(avg_acc_val))\n",
    "        print('-' * 10)\n",
    "        print()\n",
    "        \n",
    "        if avg_acc_val > best_acc:\n",
    "            best_acc = avg_acc_val\n",
    "            best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "        \n",
    "    elapsed_time = time.time() - since\n",
    "    print()\n",
    "    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print(\"Best acc: {:.4f}\".format(best_acc))\n",
    "    \n",
    "    vgg.load_state_dict(best_model_wts)\n",
    "    return vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "Training batch 0/17.0\n",
      "Validation batch 0/19\n",
      "Epoch 0 result: \n",
      "Avg loss (train): 0.0829\n",
      "Avg acc (train): 0.6466\n",
      "Avg loss (val): 0.0705\n",
      "Avg acc (val): 0.7500\n",
      "----------\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "Training batch 0/17.0\n",
      "Validation batch 0/19\n",
      "Epoch 1 result: \n",
      "Avg loss (train): 0.0857\n",
      "Avg acc (train): 0.6466\n",
      "Avg loss (val): 0.0775\n",
      "Avg acc (val): 0.6645\n",
      "----------\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "Training batch 0/17.0\n",
      "Validation batch 0/19\n",
      "Epoch 2 result: \n",
      "Avg loss (train): 0.0874\n",
      "Avg acc (train): 0.6917\n",
      "Avg loss (val): 0.0821\n",
      "Avg acc (val): 0.7171\n",
      "----------\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "Training batch 0/17.0\n",
      "Validation batch 0/19\n",
      "Epoch 3 result: \n",
      "Avg loss (train): 0.0807\n",
      "Avg acc (train): 0.6541\n",
      "Avg loss (val): 0.0732\n",
      "Avg acc (val): 0.7368\n",
      "----------\n",
      "\n",
      "\n",
      "Training completed in 28m 47s\n",
      "Best acc: 0.7500\n"
     ]
    }
   ],
   "source": [
    "vgg16 = train_model(vgg16, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=4)\n",
    "torch.save(vgg16.state_dict(), 'Explore_Australia_4e_Train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model\n",
      "----------\n",
      "Test batch 0/31\n",
      "Evaluation completed in 3m 36s\n",
      "Avg loss (test): 0.0822\n",
      "Avg acc (test): 0.7206\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "eval_model(vgg16,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model..\n",
      "Loaded!\n"
     ]
    }
   ],
   "source": [
    "# If you want to train the model for more than 2 epochs, set this to True after the first run\n",
    "resume_training = True\n",
    "\n",
    "if resume_training:\n",
    "    print(\"Loading pretrained model..\")\n",
    "    vgg16.load_state_dict(torch.load('./Explore_Australia_4e_Train.pt'))\n",
    "    print(\"Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test after 4 epoch train\n",
      "Evaluating model\n",
      "----------\n",
      "Test batch 0/31\n",
      "Evaluation completed in 3m 25s\n",
      "Avg loss (test): 0.0688\n",
      "Avg acc (test): 0.7652\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print('Test after 4 epoch train')\n",
    "eval_model(vgg16,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
