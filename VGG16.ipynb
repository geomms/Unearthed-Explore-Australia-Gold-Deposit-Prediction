{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "plt.ion()  \n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using CUDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 266 images under train\n",
      "Loaded 152 images under val\n",
      "Loaded 247 images under test\n",
      "Classes: \n",
      "['0', '1']\n"
     ]
    }
   ],
   "source": [
    "data_dir = './small/'\n",
    "TRAIN = 'train'\n",
    "VAL = 'val'\n",
    "TEST = 'test'\n",
    "\n",
    "# VGG-16 Takes 224x224 images as input, so we resize all of them\n",
    "data_transforms = {\n",
    "    TRAIN: transforms.Compose([\n",
    "        # Data augmentation is a good practice for the train set\n",
    "        # Here, we randomly crop the image to 224x224 and\n",
    "        # randomly flip it horizontally. \n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    VAL: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    TEST: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(\n",
    "        os.path.join(data_dir, x), \n",
    "        transform=data_transforms[x]\n",
    "    )\n",
    "    for x in [TRAIN, VAL, TEST]\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x], batch_size=8,\n",
    "        shuffle=True, num_workers=4\n",
    "    )\n",
    "    for x in [TRAIN, VAL, TEST]\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL, TEST]}\n",
    "\n",
    "for x in [TRAIN, VAL, TEST]:\n",
    "    print(\"Loaded {} images under {}\".format(dataset_sizes[x], x))\n",
    "    \n",
    "print(\"Classes: \")\n",
    "class_names = image_datasets[TRAIN].classes\n",
    "print(image_datasets[TRAIN].classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    # plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "\n",
    "def show_databatch(inputs, classes):\n",
    "    out = torchvision.utils.make_grid(inputs)\n",
    "    imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders[TRAIN]))\n",
    "show_databatch(inputs, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(vgg, num_images=6):\n",
    "    was_training = vgg.training\n",
    "    \n",
    "    # Set model for evaluation\n",
    "    vgg.train(False)\n",
    "    vgg.eval() \n",
    "    \n",
    "    images_so_far = 0\n",
    "\n",
    "    for i, data in enumerate(dataloaders[TEST]):\n",
    "        inputs, labels = data\n",
    "        size = inputs.size()[0]\n",
    "        \n",
    "        if use_gpu:\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            with torch.no_grad():                                  \n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        outputs = vgg(inputs)\n",
    "        \n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        predicted_labels = [preds[j] for j in range(inputs.size()[0])]\n",
    "        \n",
    "        print(\"Ground truth:\")\n",
    "        show_databatch(inputs.data.cpu(), labels.data.cpu())\n",
    "        print(\"Prediction:\")\n",
    "        show_databatch(inputs.data.cpu(), predicted_labels)\n",
    "        \n",
    "        del inputs, labels, outputs, preds, predicted_labels\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        images_so_far += size\n",
    "        if images_so_far >= num_images:\n",
    "            break\n",
    "        \n",
    "    vgg.train(mode=was_training) # Revert model back to original training state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(vgg, criterion):\n",
    "    since = time.time()\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    loss_test = 0\n",
    "    acc_test = 0\n",
    "    \n",
    "    test_batches = len(dataloaders[TEST])\n",
    "    print(\"Evaluating model\")\n",
    "    print('-' * 10)\n",
    "    \n",
    "    for i, data in enumerate(dataloaders[TEST]):\n",
    "        if i % 100 == 0:\n",
    "            print(\"\\rTest batch {}/{}\".format(i, test_batches), end='', flush=True)\n",
    "\n",
    "        vgg.train(False)\n",
    "        vgg.eval()\n",
    "        inputs, labels = data\n",
    "\n",
    "        if use_gpu:\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        outputs = vgg(inputs)\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss_test += loss.item()\n",
    "        acc_test += torch.sum(torch.eq(preds,labels)).item()\n",
    "\n",
    "        del inputs, labels, outputs, preds\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    avg_loss = loss_test / dataset_sizes[TEST]\n",
    "    avg_acc = acc_test / dataset_sizes[TEST]\n",
    "    \n",
    "    elapsed_time = time.time() - since\n",
    "    print()\n",
    "    print(\"Evaluation completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print(\"Avg loss (test): {:.4f}\".format(avg_loss))\n",
    "    print(\"Avg acc (test): {:.4f}\".format(avg_acc))\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg16 = models.vgg16_bn()\n",
    "vgg16.load_state_dict(torch.load(\"./vgg16_bn.pth\"))\n",
    "print(vgg16.classifier[6].out_features) # 1000 \n",
    "\n",
    "\n",
    "# Freeze training for all layers\n",
    "for param in vgg16.features.parameters():\n",
    "    param.require_grad = False\n",
    "\n",
    "# Newly created modules have require_grad=True by default\n",
    "num_features = vgg16.classifier[6].in_features\n",
    "features = list(vgg16.classifier.children())[:-1] # Remove last layer\n",
    "features.extend([nn.Linear(num_features, len(class_names))]) # Add our layer with 4 outputs\n",
    "vgg16.classifier = nn.Sequential(*features) # Replace the model classifier\n",
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If you want to train the model for more than 2 epochs, set this to True after the first run\n",
    "# resume_training = False\n",
    "\n",
    "# if resume_training:\n",
    "#     print(\"Loading pretrained model..\")\n",
    "#     vgg16.load_state_dict(torch.load('../input/vgg16-transfer-learning-pytorch/VGG16_v2-OCT_Retina.pt'))\n",
    "#     print(\"Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    vgg16.cuda() #.cuda() will move everything to the GPU side\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test before training\n",
      "Evaluating model\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-8c3c234bebdb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test before training\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0meval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-b7cbcfef6f13>\u001b[0m in \u001b[0;36meval_model\u001b[1;34m(vgg, criterion)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTEST\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\rTest batch {}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    717\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    103\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Test before training\")\n",
    "eval_model(vgg16, criterion)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(vgg, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    avg_loss_val = 0\n",
    "    avg_acc_val = 0\n",
    "    \n",
    "    train_batches = len(dataloaders[TRAIN])\n",
    "    val_batches = len(dataloaders[VAL])\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        loss_train = 0\n",
    "        loss_val = 0\n",
    "        acc_train = 0\n",
    "        acc_val = 0\n",
    "        \n",
    "        vgg.train(True)\n",
    "        \n",
    "        for i, data in enumerate(dataloaders[TRAIN]):\n",
    "            if i % 100 == 0:\n",
    "                print(\"\\rTraining batch {}/{}\".format(i, train_batches / 2), end='', flush=True)\n",
    "                \n",
    "            # Use half training dataset\n",
    "            if i >= train_batches / 2:\n",
    "                break\n",
    "                \n",
    "            inputs, labels = data\n",
    "            \n",
    "            if use_gpu:\n",
    "                with torch.no_grad():\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = vgg(inputs)\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            acc_train += torch.sum(torch.eq(preds,labels)).item()\n",
    "            \n",
    "            del inputs, labels, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        print()\n",
    "        # * 2 as we only used half of the dataset\n",
    "        avg_loss = loss_train * 2 / dataset_sizes[TRAIN]\n",
    "        avg_acc = acc_train * 2 / dataset_sizes[TRAIN]\n",
    "        \n",
    "        vgg.train(False)\n",
    "        vgg.eval()\n",
    "            \n",
    "        for i, data in enumerate(dataloaders[VAL]):\n",
    "            if i % 100 == 0:\n",
    "                print(\"\\rValidation batch {}/{}\".format(i, val_batches), end='', flush=True)\n",
    "                \n",
    "            inputs, labels = data\n",
    "            \n",
    "            if use_gpu:\n",
    "                with torch.no_grad():\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = vgg(inputs)\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss_val += loss.item()\n",
    "            acc_val += torch.sum(torch.eq(preds,labels)).item()\n",
    "            \n",
    "            del inputs, labels, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        avg_loss_val = loss_val / dataset_sizes[VAL]\n",
    "        avg_acc_val = acc_val / dataset_sizes[VAL]\n",
    "        \n",
    "        print()\n",
    "        print(\"Epoch {} result: \".format(epoch))\n",
    "        print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n",
    "        print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n",
    "        print(\"Avg loss (val): {:.4f}\".format(avg_loss_val))\n",
    "        print(\"Avg acc (val): {:.4f}\".format(avg_acc_val))\n",
    "        print('-' * 10)\n",
    "        print()\n",
    "        \n",
    "        if avg_acc_val > best_acc:\n",
    "            best_acc = avg_acc_val\n",
    "            best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "        \n",
    "    elapsed_time = time.time() - since\n",
    "    print()\n",
    "    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print(\"Best acc: {:.4f}\".format(best_acc))\n",
    "    \n",
    "    vgg.load_state_dict(best_model_wts)\n",
    "    return vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2\n",
      "----------\n",
      "Training batch 0/17.0\n",
      "Validation batch 0/19\n",
      "Epoch 0 result: \n",
      "Avg loss (train): 0.0878\n",
      "Avg acc (train): 0.6241\n",
      "Avg loss (val): 0.0859\n",
      "Avg acc (val): 0.6513\n",
      "----------\n",
      "\n",
      "Epoch 1/2\n",
      "----------\n",
      "Training batch 0/17.0\n",
      "Validation batch 0/19\n",
      "Epoch 1 result: \n",
      "Avg loss (train): 0.0845\n",
      "Avg acc (train): 0.6316\n",
      "Avg loss (val): 0.0834\n",
      "Avg acc (val): 0.6974\n",
      "----------\n",
      "\n",
      "\n",
      "Training completed in 17m 45s\n",
      "Best acc: 0.6974\n"
     ]
    }
   ],
   "source": [
    "vgg16 = train_model(vgg16, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=2)\n",
    "torch.save(vgg16.state_dict(), 'Explore_Australia.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model\n",
      "----------\n",
      "Test batch 0/31\n",
      "Evaluation completed in 3m 12s\n",
      "Avg loss (test): 0.0823\n",
      "Avg acc (test): 0.6964\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "eval_model(vgg16,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
